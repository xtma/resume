% \textbf{Uber Eats \hfill  San Francisco, CA} \par
% \textit{Data Analyst} \hfill Sep 2021--Dec 2021 \par
% \begin{itemize}
% 	\item Queried behavioral data on 2M eaters for segmentation via a random forests, PCA, and clustering algorithms.
% 	\item Modeled effect of discounts on Eats pass conversion and provided strategy recommendations for each cluster.
% \end{itemize} \par


\subsection*{Conference}
\begin{itemize}[leftmargin=*]
    \item \textbf{Single-Trajectory Distributionally Robust Reinforcement Learning.} \textit{Zhipeng Liang*, \textcolor{violet}{Xiaoteng Ma*}, Jose Blanchet, Jiheng Zhang, Zhengyuan Zhou.} International Conference on Machine Learning (ICML), 2024. 

    
    \item \textbf{SEABO: A Simple Search-Based Method for Offline Imitation Learning.} \textit{Jiafei Lyu, \textcolor{violet}{Xiaoteng Ma}, Le Wan, Runze Liu, Xiu Li, Zongqing Lu.} International Conference on Learning Representations (ICLR), 2024.

    \item \textbf{Learning Diverse Risk Preferences In Population-based Self-play.} \textit{Yuhua Jiang*, Qihan Liu*, \textcolor{violet}{Xiaoteng Ma}, Chenghao Li, Yiqin Yang, Jun Yang, Bin Liang, Qianchuan Zhao.} AAAI Conference on Artificial Intelligence, (AAAI), 2024. \textcolor{red}{(Oral)}

    \item \textbf{Cross-Domain Policy Adaptation via Value-Guided Data Filtering.} \textit{Kang Xu, Chenjia Bai, \textcolor{violet}{Xiaoteng Ma}, Dong Wang, Bin Zhao, Zhen Wang, Xuelong Li, Wei Li.} Advances in Neural Information Processing Systems (NeurIPS), 2023.
    
    \item \textbf{Uncertainty-driven Trajectory Truncation for Model-based Offline Reinforcement Learning.} \textit{Junjie Zhang*, Jiafei Lyu*, \textcolor{violet}{Xiaoteng Ma}, Jiangpeng Yan, Jun Yang, Le Wan, Xiu Li.} European Conference on Artificial Intelligence (ECAI), 2023.
    
    \item \textbf{What Is Essential for Unseen Goal Generalization of Offline Goal-conditioned RL?} \textit{Rui Yang, Yong Lin, \textcolor{violet}{Xiaoteng Ma}, Hao Hu, Chongjie Zhang, Tong Zhang.} International Conference on Machine Learning (ICML), 2023.    

    
    \item \textbf{RORL: Robust Offline Reinforcement Learning via Conservative Smoothing.} \textit{Rui Yang*, Chenjia Bai*, \textcolor{violet}{Xiaoteng Ma}, Zhaoran Wang, Chongjie Zhang, Lei Han.} Advances in Neural Information Processing Systems (NeurIPS), 2022. \textcolor{red}{(Spotlight)} %\href{https://arxiv.org/abs/2206.02829}{\textcolor{blue}{(arXiv link)}} 
    
    \item \textbf{Exploiting Reward Shifting in Value-Based Deep RL.} \textit{Hao Sun, Lei Han, Rui Yang, \textcolor{violet}{Xiaoteng Ma}, Jian Guo, Bolei Zhou}. Advances in Neural Information Processing Systems (NeurIPS), 2022. %\href{https://arxiv.org/abs/2209.07288}{\textcolor{blue}{(arXiv link)}}
    
    \item \textbf{Offline Reinforcement Learning with Value-based Episodic Memory.} \textit{\textcolor{violet}{Xiaoteng Ma*}, Yiqin Yang*, Hao Hu*, Qihan Liu, Jun Yang, Chongjie Zhang, Qianchuan Zhao, Bin Liang.} International Conference on Learning Representations (ICLR), 2022. %\href{https://arxiv.org/abs/2110.09796}{\textcolor{blue}{(arXiv link)}} \par
    %\textcolor{violet}{Summary:} We propose a novel offline RL algorithm VEM to keep the learning procedure within the offline dataset, which achieves superior performance in most benchmark tasks, particularly in sparse-reward tasks.
    
    \item \textbf{Efficient Continuous Control with Double Actors and Regularized Critics.} \textit{Jiafei Lyu*, \textcolor{violet}{Xiaoteng Ma*}, Jiangpeng Yan, Xiu Li.} AAAI Conference on Artificial Intelligence (AAAI), 2022. \textcolor{red}{(Oral, accept rate 3.7\%)} %\href{https://arxiv.org/abs/2106.03050}{\textcolor{blue}{(arXiv link)}}
    
    \item \textbf{Average-Reward Reinforcement Learning with Trust Region Methods.} \textit{\textcolor{violet}{Xiaoteng Ma}, Xiaohang Tang, Jun Yang, Li Xia, Qianchuan Zhao.} International Joint Conference on Artificial Intelligence (IJCAI), 2021. \textcolor{red}{(Accept rate 13.9\%)} 
    %\href{https://arxiv.org/abs/2106.03442}{\textcolor{blue}{(arXiv link)}} \par
    % \textcolor{violet}{Summary:} We provide a unified framework of the trust region approach including both the discounted and average criteria, which may complement the framework of reinforcement learning beyond the discounted objectives.

    \item \textbf{Modeling the Interaction between Agents in Cooperative Multi-Agent Reinforcement Learning.} \textit{\textcolor{violet}{Xiaoteng Ma*}, Yinqin Yang*, Chenghao Li*, Yiwen Lu, Qianchuan Zhao and Jun Yang.} International Conference on Autonomous Agents and MultiAgent Systems (AAMAS), 2021. %\href{https://arxiv.org/abs/2102.06042}{\textcolor{blue}{(arXiv link)}}
    \item \textbf{Wasserstein Distance guided Adversarial Imitation Learning with Reward Shape Exploration.} \textit{Ming Zhang*, Yawei Wang*, \textcolor{violet}{Xiaoteng Ma}, Li Xia, Jun Yang, Zhiheng Li and Xiu Li.} IEEE Data Driven Control and Learning Systems Conference (DDCLS), 2020. %\href{https://arxiv.org/abs/2006.03503}{\textcolor{blue}{(arXiv link)}}
    % \item \textbf{Fairness Control of Traffic Light via Deep Reinforcement Learning.} \textit{Chenghao Li, \textcolor{violet}{Xiaoteng Ma}, Li Xia, Qianchuan Zhao and Jun Yang.} IEEE International Conference on Automation Science and Engineering (CASE), 2020.
    % \item \textbf{Bi-level Proximal Policy optimization for Stochastic Coordination of EV Charging Load with Uncertain Wind Power.} \textit{Teng Long, \textcolor{violet}{Xiaoteng Ma}, Qing-Shan Jia.} IEEE Conference on Control Technology and Applications (CCTA), 2019.
    % \item \textbf{Attendance and security system based on building video surveillance}. \textit{Kailai Sun, Qianchuan Zhao, Jianhong Zou, \textcolor{violet}{Xiaoteng Ma}}. International Conference on Smart City and Intelligent Building (ICSCIB), 2018.
    % \item \textbf{Air-combat strategy using deep Q-learning.} \textit{\textcolor{violet}{Xiaoteng Ma}, Li Xia, Qianchuan Zhao.} Chinese Automation Congress (CAC), 2018.
\end{itemize}
\subsection*{Journal}
\begin{itemize}[leftmargin=*]
    \item \textbf{CVaR-Constrained Policy Optimization for Safe Reinforcement Learning. } \textit{Qiyuan Zhang, Shu Leng, \textcolor{violet}{Xiaoteng Ma}, Qihan Liu, Xueqian Wang, Bin Liang, Yu Liu, Jun Yang.} IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2024.
    \item \textbf{A unified algorithm framework for mean-variance optimization in discounted Markov decision processes}. \textit{Shuai Ma, \textcolor{violet}{Xiaoteng Ma}, Li Xia.}  European Journal of Operational Research (EJOR), 2023. %\href{https://arxiv.org/abs/2201.05737}{\textcolor{blue}{(arXiv link)}}
    \item \textbf{Mean-Semivariance Policy Optimization via Risk-Averse Reinforcement Learning.} \textit{\textcolor{violet}{Xiaoteng Ma}, Shuai Ma, Li Xia, Qianchuan Zhao.} Journal of Artificial Intelligence Research (JAIR), 2022. %\href{https://arxiv.org/abs/2206.07376}{\textcolor{blue}{(arXiv link)}}
    % \item \textbf{An optimistic value iteration for meanâ€“variance optimization in discounted Markov decision processes.} \textit{Shuai Ma, \textcolor{violet}{Xiaoteng Ma}, Li Xia.} Results in Control and Optimization (RICO), 2022.
    \item \textbf{MPSN: Motion-aware Pseudo-Siamese Network for Indoor Video Head Detection in Buildings.} \textit{Kailai Sun*, \textcolor{violet}{Xiaoteng Ma*}, Peng Liu*, Qianchuan Zhao.} Building and Environment (BAE), 2022. %\href{https://arxiv.org/abs/2110.03302}{\textcolor{blue}{(arXiv link)}}
    \item \textbf{Learning to Discover Task-Relevant Features for Interpretable Reinforcement Learning.} \textit{Qiyuan Zhang, \textcolor{violet}{Xiaoteng Ma}, Yiqin Yang, Chenghao Li, Jun Yang, Yu Liu and Bin Liang.} IEEE Robotics and Automation Letters (RA-L), 2021.
    % \item \textbf{Reinforcement learning for fluctuation reduction of wind power with energy storage.} \textit{Zhen Yang, \textcolor{violet}{Xiaoteng Ma}, Li Xia, Qianchuan Zhao and Xiaohong Guan.} Results in Control and Optimization (RICO), 2021.
\end{itemize}
\subsection*{Preprint}
\begin{itemize}[leftmargin=*]
    \item \textbf{Distributionally Robust Offline Reinforcement Learning with Linear Function Approximation}. \textit{\textcolor{violet}{Xiaoteng Ma*}, Zhipeng Liang*, Jose Blanchet, Mingwen Liu, Li Xia, Jiheng Zhang, Qianchuan Zhao, Zhengyuan Zhou.} %\href{https://arxiv.org/abs/2209.06620}{\textcolor{blue}{(arXiv link)}}
    \item \textbf{DSAC: Distributional Soft Actor Critic for Risk-Sensitive Reinforcement Learning}. \textit{\textcolor{violet}{Xiaoteng Ma}, Li Xia, Zhengyuan Zhou, Jun Yang and Qianchuan Zhao}.
    %\href{https://arxiv.org/abs/2004.14547}{\textcolor{blue}{(arXiv link)}}
\end{itemize}

